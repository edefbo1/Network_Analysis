{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import community as community_louvain  \n",
    "import ast\n",
    "import random\n",
    "import tarfile\n",
    "import json\n",
    "\n",
    "# Carica dati\n",
    "edges = pd.read_csv('dataset/spoti/edges.csv')\n",
    "nodes = pd.read_csv('dataset/spoti/nodes.csv')\n",
    "nodes_unique = nodes.drop_duplicates(subset=['spotify_id'], keep='first')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ESTRAZIONE MUSICBRAINZ E MAPPING NAZIONALIT√Ä\n",
    "# ============================================================================\n",
    "\n",
    "def add_nationality_to_nodes(nodes_df):\n",
    "    \"\"\"\n",
    "    Aggiunge la colonna 'nationality' al DataFrame degli artisti usando MusicBrainz.\n",
    "    \"\"\"\n",
    "    \n",
    "    # DEBUG: Verifica input\n",
    "    print(f\"üîç DEBUG - Input nodes_df type: {type(nodes_df)}\")\n",
    "    print(f\"üîç DEBUG - Input nodes_df is None: {nodes_df is None}\")\n",
    "    \n",
    "    if nodes_df is None:\n",
    "        print(\"‚ùå ERRORE: nodes_df √® None all'ingresso della funzione!\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"üîç DEBUG - nodes_df shape: {nodes_df.shape}\")\n",
    "    print(f\"üîç DEBUG - nodes_df columns: {list(nodes_df.columns)[:5]}...\")\n",
    "    \n",
    "    print(\"\\nCaricamento artisti da MusicBrainz...\")\n",
    "    artists_dict = {}\n",
    "    \n",
    "    # Leggi direttamente dal file artist\n",
    "    try:\n",
    "        with open('dataset/spoti/artist/mbdump/artist', 'r', encoding='utf-8') as f:\n",
    "            count = 0\n",
    "            matched = 0\n",
    "            for line in f:\n",
    "                try:\n",
    "                    artist = json.loads(line)\n",
    "                    name = artist.get('name', '').lower().strip()\n",
    "                    \n",
    "                    # Prendi il nome del paese dall'oggetto area\n",
    "                    area = artist.get('area')\n",
    "                    if area and isinstance(area, dict):\n",
    "                        # Verifica se √® un Country guardando i codici ISO\n",
    "                        iso_codes = area.get('iso-3166-1-codes', [])\n",
    "                        if iso_codes:  # Se ha codice ISO paese, √® un Country\n",
    "                            country_name = area.get('name')\n",
    "                            if name and country_name:\n",
    "                                if name not in artists_dict:\n",
    "                                    artists_dict[name] = country_name\n",
    "                                    matched += 1\n",
    "                    \n",
    "                    count += 1\n",
    "                    if count % 100000 == 0:\n",
    "                        print(f\"  Processati {count} artisti... (matchati: {matched})\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    continue\n",
    "        \n",
    "        print(f\"Artisti totali processati: {count}\")\n",
    "        print(f\"Artisti con nazionalit√† estratti: {len(artists_dict)}\")\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"‚ùå ERRORE: File non trovato - {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERRORE durante lettura file: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # DEBUG: Verifica dizionario\n",
    "    print(f\"\\nüîç DEBUG - artists_dict size: {len(artists_dict)}\")\n",
    "    if len(artists_dict) > 0:\n",
    "        print(f\"üîç DEBUG - Primi 3 artisti del dizionario:\")\n",
    "        for i, (name, country) in enumerate(list(artists_dict.items())[:3]):\n",
    "            print(f\"    {name} -> {country}\")\n",
    "    \n",
    "    # Aggiungi nationality al DataFrame\n",
    "    print(f\"\\nüîç DEBUG - Prima di copy(), nodes_df type: {type(nodes_df)}\")\n",
    "    \n",
    "    try:\n",
    "        nodes_df = nodes_df.copy()\n",
    "        print(f\"üîç DEBUG - Dopo copy(), nodes_df shape: {nodes_df.shape}\")\n",
    "        \n",
    "        # Verifica che esista la colonna 'name'\n",
    "        if 'name' not in nodes_df.columns:\n",
    "            print(f\"‚ùå ERRORE: Colonna 'name' non trovata!\")\n",
    "            print(f\"   Colonne disponibili: {list(nodes_df.columns)}\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"üîç DEBUG - Colonna 'name' trovata, primi 3 valori:\")\n",
    "        print(f\"    {nodes_df['name'].head(3).tolist()}\")\n",
    "        \n",
    "        nodes_df['name_lower'] = nodes_df['name'].str.lower().str.strip()\n",
    "        print(f\"üîç DEBUG - Creata colonna name_lower, primi 3 valori:\")\n",
    "        print(f\"    {nodes_df['name_lower'].head(3).tolist()}\")\n",
    "        \n",
    "        nodes_df['nationality'] = nodes_df['name_lower'].map(artists_dict)\n",
    "        print(f\"üîç DEBUG - Creata colonna nationality\")\n",
    "        \n",
    "        nodes_df.drop(columns=['name_lower'], inplace=True)\n",
    "        print(f\"üîç DEBUG - Rimossa colonna name_lower\")\n",
    "        \n",
    "        matched_nodes = nodes_df['nationality'].notna().sum()\n",
    "        total = len(nodes_df)\n",
    "        \n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"RISULTATI MATCHING\")\n",
    "        print(f\"{'='*50}\")\n",
    "        print(f\"Artisti matchati: {matched_nodes}/{total} ({100*matched_nodes/total:.1f}%)\")\n",
    "        print(f\"Artisti senza nazionalit√†: {total - matched_nodes}\")\n",
    "        \n",
    "        print(f\"\\nüîç DEBUG - Prima di return, nodes_df type: {type(nodes_df)}\")\n",
    "        print(f\"üîç DEBUG - Prima di return, nodes_df is None: {nodes_df is None}\")\n",
    "        \n",
    "        return nodes_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERRORE durante processing del DataFrame: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "\n",
    "# DEBUG: Verifica nodes_unique prima della chiamata\n",
    "print(\"=\"*70)\n",
    "print(\"VERIFICA PRIMA DELLA CHIAMATA\")\n",
    "print(\"=\"*70)\n",
    "print(f\"üîç nodes_unique type: {type(nodes_unique)}\")\n",
    "print(f\"üîç nodes_unique is None: {nodes_unique is None}\")\n",
    "if nodes_unique is not None:\n",
    "    print(f\"üîç nodes_unique shape: {nodes_unique.shape}\")\n",
    "    print(f\"üîç nodes_unique columns: {list(nodes_unique.columns)[:5]}...\")\n",
    "print()\n",
    "\n",
    "# Esegui il mapping\n",
    "result = add_nationality_to_nodes(nodes_unique)\n",
    "\n",
    "# DEBUG: Verifica risultato\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VERIFICA DOPO LA CHIAMATA\")\n",
    "print(\"=\"*70)\n",
    "print(f\"üîç result type: {type(result)}\")\n",
    "print(f\"üîç result is None: {result is None}\")\n",
    "if result is not None:\n",
    "    print(f\"üîç result shape: {result.shape}\")\n",
    "    print(f\"üîç 'nationality' in columns: {'nationality' in result.columns}\")\n",
    "    nodes_unique = result\n",
    "else:\n",
    "    print(\"‚ùå La funzione ha restituito None!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# REFINE NATIONALITY USANDO I GENERI\n",
    "# ============================================================================\n",
    "\n",
    "def refine_nationality_with_genres(nodes_df):\n",
    "    \"\"\"\n",
    "    Affina la nazionalit√† degli artisti dando priorit√† ai generi musicali\n",
    "    che contengono riferimenti geografici espliciti.\n",
    "    \n",
    "    Se un artista ha generi con keyword nazionali, sovrascrive la nationality \n",
    "    di MusicBrainz (utile per artisti con nationality mancante o ambigua).\n",
    "    \n",
    "    Parametri:\n",
    "    - nodes_df: DataFrame con colonne 'genres' e 'nationality'\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame modificato con nationality aggiornata\n",
    "    \"\"\"\n",
    "    \n",
    "    # Mapping generi -> nazionalit√† (espandibile)\n",
    "    GENRE_TO_COUNTRY = {\n",
    "        # Italia\n",
    "        \"italian\": \"Italy\",\n",
    "        \"ital\": \"Italy\",\n",
    "        \n",
    "        # Francia\n",
    "        \"french\": \"France\",\n",
    "        \"fran\": \"France\",\n",
    "        \n",
    "        # Germania\n",
    "        \"german\": \"Germany\",\n",
    "        \"deutsch\": \"Germany\",\n",
    "        \n",
    "        # Spagna\n",
    "        \"spanish\": \"Spain\",\n",
    "        \n",
    "        # UK\n",
    "        \"british\": \"United Kingdom\",\n",
    "        \"uk\": \"United Kingdom\",\n",
    "        \"english\": \"United Kingdom\",\n",
    "        \n",
    "        # USA\n",
    "        \"american\": \"United States\",\n",
    "        \n",
    "        # Nordici\n",
    "        \"swedish\": \"Sweden\",\n",
    "        \"norwegian\": \"Norway\",\n",
    "        \"danish\": \"Denmark\",\n",
    "        \"finnish\": \"Finland\",\n",
    "        \"icelandic\": \"Iceland\",\n",
    "        \n",
    "        # Altri paesi\n",
    "        \"brazilian\": \"Brazil\",\n",
    "        \"portuguese\": \"Portugal\",\n",
    "        \"mexican\": \"Mexico\",\n",
    "        \"argentinian\": \"Argentina\",\n",
    "        \"japanese\": \"Japan\",\n",
    "        \"korean\": \"South Korea\",\n",
    "        \"chinese\": \"China\",\n",
    "        \"indian\": \"India\",\n",
    "        \"turkish\": \"Turkey\",\n",
    "        \"greek\": \"Greece\",\n",
    "        \"polish\": \"Poland\",\n",
    "        \"russian\": \"Russia\",\n",
    "        \"dutch\": \"Netherlands\",\n",
    "        \"belgian\": \"Belgium\",\n",
    "        \"austrian\": \"Austria\",\n",
    "        \"swiss\": \"Switzerland\",\n",
    "        \"canadian\": \"Canada\",\n",
    "        \"australian\": \"Australia\",\n",
    "        \"irish\": \"Ireland\",\n",
    "        \"scottish\": \"United Kingdom\",  # Scozia -> UK\n",
    "        \"welsh\": \"United Kingdom\",      # Galles -> UK\n",
    "    }\n",
    "    \n",
    "    print(\"Raffinamento nazionalit√† tramite analisi dei generi...\")\n",
    "    \n",
    "    nodes_df = nodes_df.copy()\n",
    "    refined_count = 0\n",
    "    added_count = 0\n",
    "    \n",
    "    for idx, row in nodes_df.iterrows():\n",
    "        genres = row['genres']\n",
    "        current_nationality = row['nationality']\n",
    "        \n",
    "        # Salta se genres √® vuoto o NaN\n",
    "        if pd.isna(genres) or genres == '[]' or genres == '':\n",
    "            continue\n",
    "        \n",
    "        # Converti stringa di lista in stringa lowercase per il matching\n",
    "        genres_lower = str(genres).lower()\n",
    "        \n",
    "        # Cerca keyword nei generi\n",
    "        detected_country = None\n",
    "        for keyword, country in GENRE_TO_COUNTRY.items():\n",
    "            if keyword in genres_lower:\n",
    "                detected_country = country\n",
    "                break  # Prendi il primo match\n",
    "        \n",
    "        # Se troviamo una nazionalit√† nei generi\n",
    "        if detected_country:\n",
    "            # Se la nationality √® vuota, aggiungiamola\n",
    "            if pd.isna(current_nationality):\n",
    "                nodes_df.at[idx, 'nationality'] = detected_country\n",
    "                added_count += 1\n",
    "            # Se √® diversa da quella di MusicBrainz, diamo priorit√† ai generi\n",
    "            elif current_nationality != detected_country:\n",
    "                nodes_df.at[idx, 'nationality'] = detected_country\n",
    "                refined_count += 1\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"RISULTATI RAFFINAMENTO\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Nazionalit√† aggiunte (prima assenti): {added_count}\")\n",
    "    print(f\"Nazionalit√† modificate (da MusicBrainz): {refined_count}\")\n",
    "    print(f\"Totale artisti con nazionalit√†: {nodes_df['nationality'].notna().sum()}\")\n",
    "    \n",
    "    return nodes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: controlla il formato dei generi\n",
    "riria = nodes_unique[nodes_unique['name'] == 'Riria.']\n",
    "print(f\"Generi di Riria: {riria['genres'].values}\")\n",
    "print(f\"Tipo di dato: {type(riria['genres'].values[0])}\")\n",
    "\n",
    "# Se esiste la riga, stampane anche il contenuto completo\n",
    "if len(riria) > 0:\n",
    "    print(f\"\\nRiga completa:\")\n",
    "    print(riria)\n",
    "    print(f\"\\nNazionalit√† attuale: {riria['nationality'].values[0]}\")\n",
    "else:\n",
    "    print(\"‚ùå Artista 'Riria.' non trovato\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Raffina usando i generi\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 2: RAFFINAMENTO CON GENERI MUSICALI\")\n",
    "print(\"=\"*70)\n",
    "nodes_unique = refine_nationality_with_genres(nodes_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correzione: devi iterare sulle righe del DataFrame\n",
    "for idx, row in nodes_unique.iterrows():\n",
    "    if row['name'] == \"MACE\":\n",
    "        print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva nodes_unique come nuovo nodes.csv\n",
    "nodes_unique.to_csv('dataset/spoti/nodes.csv', index=False)\n",
    "print(\"‚úì File salvato: dataset/spoti/nodes.csv\")\n",
    "print(f\"  Shape: {nodes_unique.shape}\")\n",
    "print(f\"  Colonne: {list(nodes_unique.columns)}\")\n",
    "print(f\"  Artisti con nazionalit√†: {nodes_unique['nationality'].notna().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generi salvati in 'dataset/spoti/all_genres.txt'\n",
      "Numero totale di generi unici: 4853\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import sys\n",
    "\n",
    "# Carica il CSV\n",
    "df = pd.read_csv('dataset/spoti/nodes.csv', low_memory=False)\n",
    "\n",
    "# Funzione per estrarre generi dalla colonna 'genres'\n",
    "def extract_genres(genre_str):\n",
    "    try:\n",
    "        if pd.isna(genre_str) or genre_str == '[]' or genre_str == '':\n",
    "            return []\n",
    "        if isinstance(genre_str, str):\n",
    "            return ast.literal_eval(genre_str)\n",
    "        return []\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "# Estrai tutti i generi\n",
    "all_genres = []\n",
    "for genres in df['genres']:\n",
    "    all_genres.extend(extract_genres(genres))\n",
    "\n",
    "# Rimuovi duplicati e ordina\n",
    "unique_genres = sorted(set(all_genres))\n",
    "\n",
    "with open('dataset/spoti/all_genres.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(\"[\\n\")\n",
    "    for genre in unique_genres:\n",
    "        f.write(f\"    '{genre}',\\n\")\n",
    "    f.write(\"]\\n\")\n",
    "\n",
    "print(f\"Generi salvati in 'dataset/spoti/all_genres.txt'\")\n",
    "print(f\"Numero totale di generi unici: {len(unique_genres)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mappati 4855 generi.\n",
      "macro_categoria\n",
      "Altri / Specifici              1498\n",
      "Hip Hop / Rap                   523\n",
      "Pop                             498\n",
      "Elettronica / Dance             367\n",
      "Indie                           341\n",
      "Rock                            299\n",
      "Folk / Tradizionale             232\n",
      "Classica / Orchestrale          192\n",
      "Punk / Hardcore                 163\n",
      "Metal                           150\n",
      "Jazz                            122\n",
      "Reggae / Dancehall               94\n",
      "Latina / Caraibica               66\n",
      "Funk / Disco                     55\n",
      "R&B / Soul                       54\n",
      "Religiosa / Spirituale           51\n",
      "Blues                            38\n",
      "Country / Americana              36\n",
      "Soundtrack / Colonne sonore      36\n",
      "World / Etnica                   31\n",
      "Commedia / Satira                 9\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "with open('dataset/spoti/all_genres.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Estrai i generi\n",
    "genres = [line.strip().strip(\"',[]\") for line in lines if line.strip() and not line.startswith('Numero') and not line.startswith('Array')]\n",
    "\n",
    "# Regole base di mappatura\n",
    "def map_genre(genre):\n",
    "    genre_lower = genre.lower()\n",
    "    \n",
    "    if 'pop' in genre_lower or 'pop' == genre_lower:\n",
    "        return 'Pop'\n",
    "    elif 'rock' in genre_lower:\n",
    "        return 'Rock'\n",
    "    elif any(word in genre_lower for word in ['hip hop', 'rap', 'trap', 'drill', 'boom bap', 'grime']):\n",
    "        return 'Hip Hop / Rap'\n",
    "    elif any(word in genre_lower for word in ['electronic', 'techno', 'house', 'trance', 'ambient', 'dubstep', 'dnb', 'drum and bass', 'edm', 'breakbeat', 'hardstyle', 'electro', 'idm', 'chiptune', 'vaporwave', 'lo-fi', 'synth']):\n",
    "        return 'Elettronica / Dance'\n",
    "    elif 'jazz' in genre_lower:\n",
    "        return 'Jazz'\n",
    "    elif any(word in genre_lower for word in ['classical', 'orchestra', 'choir', 'baroque', 'symphony', 'concerto', 'chamber', 'opera', 'piano solo', 'violin solo']):\n",
    "        return 'Classica / Orchestrale'\n",
    "    elif any(word in genre_lower for word in ['folk', 'traditional', 'acoustic', 'singer-songwriter', 'americana', 'bluegrass']):\n",
    "        return 'Folk / Tradizionale'\n",
    "    elif any(word in genre_lower for word in ['country', 'americana', 'honky tonk', 'western']):\n",
    "        return 'Country / Americana'\n",
    "    elif 'blues' in genre_lower:\n",
    "        return 'Blues'\n",
    "    elif 'metal' in genre_lower:\n",
    "        return 'Metal'\n",
    "    elif any(word in genre_lower for word in ['punk', 'hardcore', 'emo', 'screamo', 'post-hardcore']):\n",
    "        return 'Punk / Hardcore'\n",
    "    elif any(word in genre_lower for word in ['funk', 'disco', 'boogie']):\n",
    "        return 'Funk / Disco'\n",
    "    elif any(word in genre_lower for word in ['r&b', 'soul', 'motown', 'neo-soul']):\n",
    "        return 'R&B / Soul'\n",
    "    elif any(word in genre_lower for word in ['reggae', 'dancehall', 'ska', 'rocksteady', 'dub']):\n",
    "        return 'Reggae / Dancehall'\n",
    "    elif any(word in genre_lower for word in ['latin', 'salsa', 'bachata', 'cumbia', 'merengue', 'reggaeton', 'tango', 'samba', 'bossanova', 'forro']):\n",
    "        return 'Latina / Caraibica'\n",
    "    elif any(word in genre_lower for word in ['gospel', 'christian', 'worship', 'religious', 'spiritual', 'ccm']):\n",
    "        return 'Religiosa / Spirituale'\n",
    "    elif any(word in genre_lower for word in ['soundtrack', 'score', 'theme', 'ost', 'film music', 'video game music']):\n",
    "        return 'Soundtrack / Colonne sonore'\n",
    "    elif any(word in genre_lower for word in ['comedy', 'parody', 'humor', 'satire']):\n",
    "        return 'Commedia / Satira'\n",
    "    elif any(word in genre_lower for word in ['world', 'ethnic', 'african', 'arab', 'indian', 'celtic', 'flamenco', 'klezmer', 'oriental']):\n",
    "        return 'World / Etnica'\n",
    "    elif any(word in genre_lower for word in ['indie', 'Indie']):\n",
    "        return 'Indie'\n",
    "    else:\n",
    "        return 'Altri / Specifici'\n",
    "\n",
    "mapped = [(genre, map_genre(genre)) for genre in genres]\n",
    "df = pd.DataFrame(mapped, columns=['genere', 'macro_categoria'])\n",
    "\n",
    "# Salva in CSV\n",
    "df.to_csv('dataset/spoti/all_genres_mapped.csv', index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"Mappati {len(df)} generi.\")\n",
    "print(df['macro_categoria'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di generi nella categoria 'Altri / Specifici': 1498\n",
      "Lista salvata in 'dataset/spoti/other_genres.txt'\n",
      "2. 432hz\n",
      "3. 48g\n",
      "4. 8-bit\n",
      "5. 8d\n",
      "6. a cappella\n",
      "7. a3\n",
      "8. abstract\n",
      "9. abstract beats\n",
      "10. abstractro\n",
      "11. accordion\n",
      "12. acousmatic\n",
      "13. adoracao\n",
      "14. adoracion\n",
      "15. adult standards\n",
      "16. adventista\n",
      "17. afrikaans\n",
      "18. afro-cuban percussion\n",
      "19. afrobeat\n",
      "20. afrobeat brasileiro\n",
      "\n",
      "Generi validi (non vuoti): 1496\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('dataset/spoti/all_genres_mapped.csv')\n",
    "\n",
    "# Estraggo tutti le righe con: \"Altri / Specifici\"\n",
    "altri_generi = df[df['macro_categoria'] == 'Altri / Specifici']\n",
    "\n",
    "num_altri = len(altri_generi)\n",
    "print(f\"Numero di generi nella categoria 'Altri / Specifici': {num_altri}\")\n",
    "\n",
    "nomi_generi = []\n",
    "for genere in altri_generi['genere']:\n",
    "    if pd.isna(genere):\n",
    "        nomi_generi.append('')\n",
    "    elif isinstance(genere, float):\n",
    "        nomi_generi.append(str(int(genere)) if genere.is_integer() else str(genere))\n",
    "    else:\n",
    "        nomi_generi.append(str(genere))\n",
    "\n",
    "with open('dataset/spoti/other_genres.txt', 'w', encoding='utf-8') as f:\n",
    "    for genere in nomi_generi:\n",
    "        if genere.strip():  # Salta righe vuote\n",
    "            f.write(genere + '\\n')\n",
    "\n",
    "print(f\"Lista salvata in 'dataset/spoti/other_genres.txt'\")\n",
    "for i, genere in enumerate(nomi_generi[:20]):\n",
    "    if genere.strip():\n",
    "        print(f\"{i+1}. {genere}\")\n",
    "\n",
    "validi = sum(1 for g in nomi_generi if g.strip())\n",
    "print(f\"\\nGeneri validi (non vuoti): {validi}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File generato con successo: dataset/spoti/all_genres_mapped_v2.csv\n",
      "Totale generi mappati: 1492\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df = pd.read_csv('dataset/spoti/all_genres_mapped.csv')\n",
    "\n",
    "# Leggi il file txt con la mappatura eseguita con l'AI separatamente\n",
    "with open('dataset/spoti/ai_mapped_genres.txt', 'r', encoding='utf-8') as f:\n",
    "    contenuto = f.read()\n",
    "\n",
    "mappatura_generi = {}\n",
    "macro_categoria_corrente = None\n",
    "\n",
    "for linea in contenuto.split('\\n'):\n",
    "    linea = linea.strip()\n",
    "    \n",
    "    if linea.startswith('## **') and linea.endswith('**'):\n",
    "        macro_categoria_corrente = linea.replace('## **', '').replace('**', '').strip()\n",
    "    elif linea and not linea.startswith('#') and macro_categoria_corrente:\n",
    "        mappatura_generi[linea.lower()] = macro_categoria_corrente\n",
    "\n",
    "# Aggiorna il dataframe: per ogni riga con macro_categoria \"Altri / Specifici\", cerca il genere corrispondente nel dizionario di mappatura\n",
    "df.loc[df['macro_categoria'] == 'Altri / Specifici', 'macro_categoria'] = \\\n",
    "    df.loc[df['macro_categoria'] == 'Altri / Specifici', 'genere'].str.lower().map(mappatura_generi)\n",
    "\n",
    "df.to_csv('dataset/spoti/all_genres_mapped_v2.csv', index=False)\n",
    "\n",
    "print(\"File generato con successo: dataset/spoti/all_genres_mapped_v2.csv\")\n",
    "print(f\"Totale generi mappati: {len(mappatura_generi)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File generato con successo: nodes2.csv\n",
      "Totale righe processate: 156320\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "nodes_df = pd.read_csv('dataset/spoti/nodes.csv', low_memory=False)\n",
    "generi_df = pd.read_csv('dataset/spoti/all_genres_mapped_v2.csv')\n",
    "\n",
    "mappatura = dict(zip(generi_df['genere'].str.lower(), generi_df['macro_categoria']))\n",
    "\n",
    "def ottieni_macro_genres(generi_str, row_index):\n",
    "    if pd.isna(generi_str):\n",
    "        return '[]'\n",
    "    \n",
    "    try:\n",
    "        generi_list = ast.literal_eval(generi_str)\n",
    "        \n",
    "        macro_genres = []\n",
    "        generi_non_trovati = []\n",
    "        \n",
    "        for genere in generi_list:\n",
    "            genere_lower = genere.lower().strip()\n",
    "            if genere_lower in mappatura:\n",
    "                macro_cat = mappatura[genere_lower]\n",
    "                if macro_cat not in macro_genres:\n",
    "                    macro_genres.append(macro_cat)\n",
    "            else:\n",
    "                generi_non_trovati.append(genere)\n",
    "        \n",
    "        if generi_non_trovati:\n",
    "            print(f\"Riga {row_index}: Generi non mappati: {generi_non_trovati}\")\n",
    "        \n",
    "        return str(macro_genres)\n",
    "    except Exception as e:\n",
    "        print(f\"Riga {row_index}: Errore nel parsing: {e}\")\n",
    "        return '[]'\n",
    "\n",
    "nodes_df['macro_genres'] = nodes_df.apply(lambda row: ottieni_macro_genres(row['genres'], row.name), axis=1)\n",
    "nodes_df.to_csv('dataset/spoti/nodes2.csv', index=False)\n",
    "#nodes_df.to_csv('dataset/spoti/nodes.csv', index=False)\n",
    "\n",
    "print(\"File generato con successo: 'dataset/spoti/nodes2.csv'\")\n",
    "print(f\"Totale righe processate: {len(nodes_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "STATISTICHE GENRES VUOTI\n",
      "==================================================\n",
      "Totale righe: 156320\n",
      "\n",
      "Genres vuoti []: 102121 (65.33%)\n",
      "Macro_genres vuoti []: 102121 (65.33%)\n",
      "Entrambi vuoti []: 102121 (65.33%)\n",
      "\n",
      "Genres NON vuoto ma Macro_genres vuoto []: 0 (0.00%)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "nodes_df = pd.read_csv('dataset/spoti/nodes2.csv', low_memory=False)\n",
    "\n",
    "def is_empty_array(value):\n",
    "    if pd.isna(value):\n",
    "        return True\n",
    "    \n",
    "    try:\n",
    "        parsed = ast.literal_eval(str(value))\n",
    "        return len(parsed) == 0\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# Conta gli elementi con genres vuoti\n",
    "genres_vuoti = nodes_df['genres'].apply(is_empty_array).sum()\n",
    "\n",
    "# Conta gli elementi con macro_genres vuoti\n",
    "macro_genres_vuoti = nodes_df['macro_genres'].apply(is_empty_array).sum()\n",
    "\n",
    "# Conta gli elementi che hanno entrambi vuoti\n",
    "entrambi_vuoti = (nodes_df['genres'].apply(is_empty_array) & \n",
    "                  nodes_df['macro_genres'].apply(is_empty_array)).sum()\n",
    "\n",
    "# Conta gli elementi con genres non vuoto ma macro_genres vuoto\n",
    "genres_pieni_macro_vuoti = (~nodes_df['genres'].apply(is_empty_array) & \n",
    "                             nodes_df['macro_genres'].apply(is_empty_array)).sum()\n",
    "\n",
    "# Statistiche\n",
    "totale_righe = len(nodes_df)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"STATISTICHE GENRES VUOTI\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Totale righe: {totale_righe}\")\n",
    "print(f\"\\nGenres vuoti []: {genres_vuoti} ({genres_vuoti/totale_righe*100:.2f}%)\")\n",
    "print(f\"Macro_genres vuoti []: {macro_genres_vuoti} ({macro_genres_vuoti/totale_righe*100:.2f}%)\")\n",
    "print(f\"Entrambi vuoti []: {entrambi_vuoti} ({entrambi_vuoti/totale_righe*100:.2f}%)\")\n",
    "print(f\"\\nGenres NON vuoto ma Macro_genres vuoto []: {genres_pieni_macro_vuoti} ({genres_pieni_macro_vuoti/totale_righe*100:.2f}%)\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operazione completata.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Lista dei file d'appoggio da cancellare\n",
    "files_to_delete = [\n",
    "    'dataset/spoti/all_genres.txt',\n",
    "    'dataset/spoti/all_genres_mapped.csv',\n",
    "    'dataset/spoti/other_genres.txt',\n",
    "    'dataset/spoti/all_genres_mapped_v2.csv'\n",
    "]\n",
    "\n",
    "# Cancella i file\n",
    "for file_path in files_to_delete:\n",
    "    try:\n",
    "        if os.path.exists(file_path):\n",
    "            os.remove(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\" Errore nella cancellazione di {file_path}: {e}\\n\")\n",
    "\n",
    "print(\"Operazione completata.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
